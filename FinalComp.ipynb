{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c747cd-9ee2-42fb-8142-3e7323924ea9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71303b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-craigslist in c:\\users\\exor6\\anaconda3\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: six in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from python-craigslist) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from python-craigslist) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9.0 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from python-craigslist) (4.11.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from python-craigslist) (1.26.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.9.0->python-craigslist) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from requests>=2.25.0->python-craigslist) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from requests>=2.25.0->python-craigslist) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\exor6\\anaconda3\\lib\\site-packages (from requests>=2.25.0->python-craigslist) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "! pip install python-craigslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb574a4-dfec-49a7-8463-6bf14594ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Soup and create parser\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from craigslist import CraigslistForSale\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "from numpy import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ded4f8-e312-4192-b8e9-488e8ebb24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the body of the text\n",
    "def find_body_text(soup):\n",
    "    body = soup.find(\"section\", {\"id\": \"postingbody\"})\n",
    "    body_text = \"\"\n",
    "    try:\n",
    "        body_text = body.find_all(text=True, recursive = False)[1]\n",
    "    except:\n",
    "        None\n",
    "    return body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11998155-2c00-4b7a-95df-d92e696546c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_title_text(soup):\n",
    "    title = soup.find(\"span\", {\"id\": \"titletextonly\"})\n",
    "    title_text = title.text\n",
    "    return title_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac167b6-def0-4a79-937a-86057c2d1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do a try expect for empty image set\n",
    "def find_image_list(soup):\n",
    "    image_links = []\n",
    "    image = soup.find(\"div\", {\"id\": \"thumbs\"})\n",
    "    try:\n",
    "        image_anchors = image.find_all(\"a\", {\"class\": \"thumb\"})\n",
    "        for i in image_anchors:\n",
    "            image_links.append(i[\"href\"])\n",
    "    except:\n",
    "        None\n",
    "    return image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a5b76ae-ad43-48f5-8a78-c8ad3147c563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tippecanoe Furnature Listing Count: 184\n",
      "Indianapolis Furnature Listing Count: 1545\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m cl_tp\u001b[38;5;241m.\u001b[39mget_results(sort_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewest\u001b[39m\u001b[38;5;124m'\u001b[39m, geotagged\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m     URL \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# structure\n",
    "# id: {title: \"Text\"\n",
    "#      description: \"Text\"\n",
    "#      region: \"location\"  \n",
    "#      images: [\"url1\", \"url2\", \"url3\"]}\n",
    "listings = {}\n",
    "\n",
    "\n",
    "# create the Craiglist object for tippecanoe furnature\n",
    "cl_tp = CraigslistForSale(site='tippecanoe', category='fua')\n",
    "print(\"Tippecanoe Furnature Listing Count: {}\".format(cl_tp.get_results_approx_count()))\n",
    "\n",
    "cl_indy = CraigslistForSale(site=\"indianapolis\", category ='fua')\n",
    "print(\"Indianapolis Furnature Listing Count: {}\".format(cl_indy.get_results_approx_count()))\n",
    "\n",
    "\n",
    "count = 0\n",
    "# iterate through the results to pull the id and the url of each listing\n",
    "for result in cl_tp.get_results(sort_by='newest', geotagged=True):\n",
    "    URL = result['url']\n",
    "    sleep(random.uniform(2,3))\n",
    "    clear_output(wait=True)\n",
    "    count+=1\n",
    "    print(\"Pulling request {}: {}\".format(count, URL))\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    holder = {}\n",
    "    holder['region'] = \"tippecanoe\"\n",
    "    holder['title'] = find_title_text(soup)\n",
    "    holder['description'] = find_body_text(soup)\n",
    "    holder['images'] = find_image_list(soup)\n",
    "    \n",
    "    listings[result[\"id\"]] = holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d67f0-7c69-4765-867c-02b808249543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the results for indy\n",
    "count = 0\n",
    "\n",
    "for result in cl_indy.get_results(sort_by='newest', geotagged=True):\n",
    "    URL = result['url']\n",
    "    sleep(random.uniform(2,3))\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    count += 1\n",
    "    clear_output(wait=True)\n",
    "    print(\"Pulling request {}: {}\".format(count, URL))\n",
    "    \n",
    "    holder = {}\n",
    "    holder['region'] = \"indianoplis\"\n",
    "    holder['title'] = find_title_text(soup)\n",
    "    holder['description'] = find_body_text(soup)\n",
    "    holder['images'] = find_image_list(soup)\n",
    "    \n",
    "    listings[result[\"id\"]] = holder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3221d-3b5c-4822-b303-316f5df924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(listings, indent = 4)\n",
    "with open(\"listings.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b05ad9-beda-418a-b2ee-00cc0527febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the json to csv for submission\n",
    "with open(\"listings.json\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "listings = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafa00c-4e27-4634-a6e2-b66ff6bccb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn json into csv as per the requirements\n",
    "# Only useful the first time, hard coded labels into the xlsx file\n",
    "\n",
    "import csv\n",
    "\n",
    "header = [\"id\", \"region\", \"title\", \"description\", \"images\", \"label\"]\n",
    "fname = \"listings.csv\"\n",
    "with open(fname, 'w', encoding = \"UTF8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    for i in listings:\n",
    "        row=[]\n",
    "        row.append(i)\n",
    "        row.append(listings[i][\"region\"])\n",
    "        row.append(listings[i][\"title\"])\n",
    "        row.append(listings[i][\"description\"][1:])\n",
    "        row.append(listings[i][\"images\"])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9165e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4605d87",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forest Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8202436-3fb6-4a02-af6f-3a9a96dd6fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Austi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Austi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Austi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Austi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Austi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2e6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading excel file that was scrapped from Craigslist\n",
    "df = pd.read_excel('listings.xlsx')[:1299]\n",
    "df = df.iloc[:1299, :-1]\n",
    "def latin_utf8(text):\n",
    "    try:\n",
    "        return text.encode(\"latin1\").decode(\"utf8\")\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "for col in ['title','description']:\n",
    "    # fix the php and html parsing issues\n",
    "    df[col] = df[col].apply(lambda text: html.unescape(str(text)))\n",
    "    # fix no space after period\n",
    "    df[col] = df[col].apply(lambda text: re.sub(r'[\\.]', \" \", text))\n",
    "    # fix the latin encoding issue for décor\n",
    "    df[col] = df[col].apply(lambda text: latin_utf8(text))\n",
    "\n",
    "    # remove and punctuation and replace with blank don't => dont, this will help fix some spelling and grammar issues\n",
    "    df[col] = df[col].apply(lambda text: re.sub(r'[^\\w\\s]', \"\", text))\n",
    "    \n",
    "# combining title and description into a string\n",
    "df['combined'] = df['title']+ ' ' +df['description']\n",
    "\n",
    "#divide data into train and test set\n",
    "train = df.sample(frac=0.9)\n",
    "test = df.drop(train.index)\n",
    "X_train = train['combined']\n",
    "X_test = test['combined']\n",
    "y_train = train['label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7f87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train pre processing\n",
    "X_train_token = [nltk.word_tokenize(str(l)) for l in X_train]\n",
    "remove_list = list(string.punctuation)+stopwords.words('english')\n",
    "X_train_token = [[word.lower() for word in review if word.lower() not in remove_list and word.isalpha()] for review in X_train_token]\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "X_train_lemm = []\n",
    "for review in X_train_token:\n",
    "    lemreview = []\n",
    "    for token in review:\n",
    "        lemm = lemmatizer.lemmatize(token)\n",
    "        lemreview.append(lemm)\n",
    "    X_train_lemm.append(lemreview)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5,ngram_range=(1,2))\n",
    "X_train_processed = []\n",
    "for review in X_train_lemm:\n",
    "    review = ' '.join(review)\n",
    "    X_train_processed.append(review)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_processed).toarray()\n",
    "\n",
    "# X_test pre processing\n",
    "X_test_token = [nltk.word_tokenize(str(l)) for l in X_test]\n",
    "X_test_token = [[word.lower() for word in review if word.lower() not in remove_list and word.isalpha()] for review in X_test_token]\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "X_test_lemm = []\n",
    "for review in X_test_token:\n",
    "    lemreview = []\n",
    "    for token in review:\n",
    "        lemm = lemmatizer.lemmatize(token)\n",
    "        lemreview.append(lemm)\n",
    "    X_test_lemm.append(lemreview)\n",
    "\n",
    "X_test_processed = []\n",
    "for review in X_test_lemm:\n",
    "    review = ' '.join(review)\n",
    "    X_test_processed.append(review)\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test_processed).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14314ae4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forest Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68453326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9948674080410608\n",
      "Test Score:  0.8\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Test\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train_tfidf,y_train)\n",
    "y_test_pred_rf = rf.predict(X_test_tfidf)\n",
    "y_train_pred_rf = rf.predict(X_train_tfidf)\n",
    "score_train_rf = accuracy_score(y_train,y_train_pred_rf)\n",
    "score_test_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "print(\"Train Score: \",score_train_rf)\n",
    "print(\"Test Score: \",score_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec818f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataframe with ID, Title_Description, Predicted Label, Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de8374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_description</th>\n",
       "      <th>label</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7565015560</td>\n",
       "      <td>Entertainment Center and Hall Tree The Custom ...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.679405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7564716075</td>\n",
       "      <td>Love seat w recliner This faux leather love se...</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7562281392</td>\n",
       "      <td>FullDouble Mattress  Never Slept In 11 inch Co...</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7561155451</td>\n",
       "      <td>Hanging Fruit Hanging glass fruit Never been used</td>\n",
       "      <td>storage</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7551850196</td>\n",
       "      <td>Benchpadded Sturdy bench</td>\n",
       "      <td>storage</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7556947693</td>\n",
       "      <td>bedroom dresser and mirror Arbek oak dresser a...</td>\n",
       "      <td>storage</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>7556847085</td>\n",
       "      <td>Granite Topped Bombay End Table Nightstand Gra...</td>\n",
       "      <td>table</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7556733354</td>\n",
       "      <td>Pottery Barn Corner Desk Large white corner de...</td>\n",
       "      <td>table</td>\n",
       "      <td>0.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7556246473</td>\n",
       "      <td>Modern sectional sofa Modern gray sectional so...</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7556241182</td>\n",
       "      <td>WOODEN CHAIR ANTIQUE VINTAGE Strong wooden chair</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                  title_description  \\\n",
       "0    7565015560  Entertainment Center and Hall Tree The Custom ...   \n",
       "1    7564716075  Love seat w recliner This faux leather love se...   \n",
       "2    7562281392  FullDouble Mattress  Never Slept In 11 inch Co...   \n",
       "3    7561155451  Hanging Fruit Hanging glass fruit Never been used   \n",
       "4    7551850196                          Benchpadded Sturdy bench    \n",
       "..          ...                                                ...   \n",
       "125  7556947693  bedroom dresser and mirror Arbek oak dresser a...   \n",
       "126  7556847085  Granite Topped Bombay End Table Nightstand Gra...   \n",
       "127  7556733354  Pottery Barn Corner Desk Large white corner de...   \n",
       "128  7556246473  Modern sectional sofa Modern gray sectional so...   \n",
       "129  7556241182   WOODEN CHAIR ANTIQUE VINTAGE Strong wooden chair   \n",
       "\n",
       "             label     proba  \n",
       "0    entertainment  0.679405  \n",
       "1          seating  0.890000  \n",
       "2         sleeping  0.680000  \n",
       "3          storage  0.410000  \n",
       "4          storage  0.300000  \n",
       "..             ...       ...  \n",
       "125        storage  0.840000  \n",
       "126          table  0.660000  \n",
       "127          table  0.695000  \n",
       "128        seating  0.900000  \n",
       "129        seating  0.940000  \n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_mat = pd.DataFrame(rf.predict_proba(X_test_tfidf)).apply(lambda x: x.max(),axis=1)\n",
    "labels = pd.Series(y_test_pred_rf)\n",
    "combined = pd.Series(X_test).reset_index().drop('index',axis=1)\n",
    "df_proba = pd.concat([test['id'].reset_index().drop('index',axis=1),combined,labels,proba_mat],axis=1)\n",
    "df_proba.columns = ['id','title_description','label','proba']\n",
    "df_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25da40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0e869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.python.keras import optimizers, regularizers\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import glob\n",
    "from datasets.utils.file_utils import get_datasets_user_agent\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1913a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading the images (Only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b83bde67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the xlsx\n",
    "# downloading the images to the right directory from craiglist, only the first image, based on label\n",
    "\n",
    "#df_load = pd.read_excel(r'listings.xlsx')\n",
    "\n",
    "#df = df_load.iloc[:1299, :-1]\n",
    "\n",
    "\n",
    "df[\"images\"] = df[\"images\"].apply(literal_eval)\n",
    "path = \"Data/train/\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # list of images from listing\n",
    "    image_list = row[\"images\"]\n",
    "    \n",
    "    #pull the first image in the list\n",
    "    try:\n",
    "        image_url = image_list[0]\n",
    "    except:\n",
    "        continue\n",
    "    #set to listing id\n",
    "    image_id = row[\"id\"]\n",
    "    label = row[\"label\"]\n",
    "    image_path = path + \"cl_\" + label + \"/\" + str(image_id) +\".jpg\"\n",
    "    USER_AGENT = get_datasets_user_agent()\n",
    "    \n",
    "    #if the image_url is empty this will break\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        image_url,\n",
    "        data=None,\n",
    "        headers={\"user-agent\": USER_AGENT},\n",
    "    )\n",
    "\n",
    "    if not os.path.isfile(image_path):\n",
    "        with urllib.request.urlopen(request, timeout=None) as req:\n",
    "            image = Image.open(io.BytesIO(req.read()))\n",
    "            image.save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35aeb5",
   "metadata": {},
   "source": [
    "### Creating the data to feed to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28157e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mapping of the cl_id, filepath and label\n",
    "mappings = pd.DataFrame(columns = [\"id\",\"filepath\",\"label\"], index=[\"\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659ed4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d55b66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### maps every image path to a label for training\n",
    "\n",
    "path = \"Data/train\"\n",
    "# get all folders in train set\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        directory = entry.name\n",
    "        label = \"\"\n",
    "        cl = False\n",
    "        cl_id = -1\n",
    "        \n",
    "        if directory == \"bed\":\n",
    "            label = \"sleeping\"\n",
    "        elif directory in [\"sofa\", \"chair\", \"swivelchair\"]:\n",
    "            label = \"seating\"\n",
    "        elif directory == \"table\":\n",
    "            label = \"table\"\n",
    "        elif directory[:3] == \"cl_\":\n",
    "            label = directory[3:]\n",
    "            cl = True\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        #get all images in a specific folder\n",
    "        directory_path = path +\"/\"+entry.name\n",
    "        with os.scandir(directory_path) as files:\n",
    "            for file in files:\n",
    "                img_path = directory_path + \"/\" + file.name\n",
    "                \n",
    "                #This is not a good way to do this and should be refactored\n",
    "                if cl:\n",
    "                    cl_id = file.name[:-4]\n",
    "                    \n",
    "                mappings.loc[len(mappings.index)] = [cl_id, img_path, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb04f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the test set for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0145d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df=pd.DataFrame(columns = [\"id\",\"filepath\",\"true_label\", \"prediction\", \"proba\"], index=[\"\"]).dropna()\n",
    "\n",
    "# for some reason cant merge unless both str\n",
    "test = test.astype({'id':'str'})\n",
    "mappings = mappings.astype({'id': 'str'})\n",
    "\n",
    "\n",
    "# expect some NaN for filepath as the not all have pictures\n",
    "test_df = pd.merge(test, mappings, on='id', how='left')\n",
    "test_df = test_df.rename(columns={\"label_x\": \"label\", \"label_y\": \"prediction_NN\"})\n",
    "test_df[\"prediction_NN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9ad8323-efa4-4eb3-8023-5eb517ed79b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7439, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7119f7d7-177e-41a6-8274-a991a7d8b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = mappings\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    cl_id = row['id']\n",
    "    train_val_df.drop(train_val_df[train_val_df['id']==cl_id].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "693f9330-7116-4395-81b6-619edd280136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7347, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347223b",
   "metadata": {},
   "source": [
    "### Training RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b16c6d",
   "metadata": {},
   "source": [
    "### Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ab72bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Xception(include_top=False, pooling='avg', weights=\"imagenet\"))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.layers[0].trainable = False\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09bf614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6245 validated image filenames belonging to 6 classes.\n",
      "Found 1102 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 299\n",
    "BATCH_TRAIN = 16\n",
    "BATCH_VAL = 16\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                             rescale=1./255.,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             validation_split=0.15)\n",
    "\n",
    "# removed the directory=r\"./furniture_images/\", arg\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=train_val_df,\n",
    "                        x_col=\"filepath\",\n",
    "                        y_col=\"label\",has_ext=False,\n",
    "                        subset=\"training\",batch_size=BATCH_TRAIN,\n",
    "                        shuffle=True,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(image_size, image_size))\n",
    "\n",
    "# removed the directory=r\"./furniture_images\", arg\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "                        dataframe=train_val_df,\n",
    "                        x_col=\"filepath\",\n",
    "                        y_col=\"label\",has_ext=False,\n",
    "                        subset=\"validation\",batch_size=BATCH_VAL,\n",
    "                        class_mode=\"categorical\",target_size=(image_size, image_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43c699",
   "metadata": {},
   "source": [
    "#### Verify GPU CUDA is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fdad069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17118025501331182959\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5762973696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18147099931162551604\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ef2d4",
   "metadata": {},
   "source": [
    "### Train the model (skip and use loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2eff17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "390/390 [==============================] - 145s 369ms/step - loss: 0.7963 - accuracy: 0.7510 - val_loss: 2.7067 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "390/390 [==============================] - 145s 374ms/step - loss: 0.5386 - accuracy: 0.8343 - val_loss: 2.7169 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8497"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3516\\749436940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msteps_per_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mBATCH_VAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(train_generator,\n\u001b[0m\u001b[0;32m      5\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1216\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1218\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1219\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1497\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1498\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps_per_train = int(np.ceil(train_generator.n / BATCH_TRAIN))\n",
    "steps_per_val = int(np.ceil(train_generator.n / BATCH_VAL))\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=steps_per_train,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=steps_per_val,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eb9d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "### uncomment based on what you are doing\n",
    "\n",
    "# save the model\n",
    "# model.save('trained1_model')\n",
    "\n",
    "# load the model\n",
    "# from tensorflow import keras\n",
    "# model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f2410",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf5648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entertainment', 'other', 'seating', 'sleeping', 'storage', 'table']\n",
      "0.35555555555555557\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from tensorflow.keras.utils import load_img,img_to_array\n",
    "\n",
    "# def load(filename):\n",
    "#     np_image = Image.open(filename)\n",
    "#     np_image = np.array(np_image).astype('float32')/255\n",
    "#     np_image = transform.resize(np_image, (299, 299, 3))\n",
    "#     np_image = np.expand_dims(np_image, axis=0)\n",
    "#     return np_image\n",
    "\n",
    "def load(filename):\n",
    "    img = load_img(filename, target_size=(299,299))\n",
    "    #convert image to array\n",
    "    input_img = img_to_array(img)\n",
    "    input_img = np.expand_dims(input_img, axis=0)\n",
    "    input_img = preprocess_input(input_img)\n",
    "    return input_img\n",
    "\n",
    "# get the list of labels and there indexs\n",
    "labels = (train_generator.class_indices)\n",
    "labels = list(labels.keys())\n",
    "print(labels)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "    \n",
    "for index, row in test_df.iterrows():\n",
    "    try:\n",
    "        img = load(row[\"filepath\"])\n",
    "        pred = model.predict(img)\n",
    "        pred = list(pred[0])\n",
    "        prob = max(pred)\n",
    "        lab = labels[pred.index(prob)]\n",
    "        test_df.loc[test_df.index == index, \"prediction_NN\"] = lab\n",
    "        test_df.loc[test_df.index == index, \"proba_NN\"] = prob\n",
    "        total += 1\n",
    "        if lab == row[\"label\"]:\n",
    "            correct += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba8d99-e63e-45df-b371-09dd1b423c77",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16053164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up\n",
    "df_proba = df_proba.astype({'id':'str'})\n",
    "test_df = test_df.astype({'id': 'str'})\n",
    "test_df = test_df.drop([\"description\", \"region\", \"combined\"], axis = 1)\n",
    "\n",
    "df_proba = df_proba.rename(columns={\"label\": \"prediction_rf\", \"proba\": \"proba_rf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f00b97d-10bc-4c7b-889c-b6df9eab6ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_description</th>\n",
       "      <th>prediction_rf</th>\n",
       "      <th>proba_rf</th>\n",
       "      <th>title</th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>prediction_NN</th>\n",
       "      <th>proba_NN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7565015560</td>\n",
       "      <td>Entertainment Center and Hall Tree The Custom ...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.679405</td>\n",
       "      <td>Entertainment Center and Hall Tree</td>\n",
       "      <td>['https://images.craigslist.org/00S0S_fi2XJS06...</td>\n",
       "      <td>other</td>\n",
       "      <td>Data/train/cl_other/7565015560.jpg</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.200292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7564716075</td>\n",
       "      <td>Love seat w recliner This faux leather love se...</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>Love seat w recliner</td>\n",
       "      <td>['https://images.craigslist.org/01515_1WBeEG4z...</td>\n",
       "      <td>seating</td>\n",
       "      <td>Data/train/cl_seating/7564716075.jpg</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.208093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7562281392</td>\n",
       "      <td>FullDouble Mattress  Never Slept In 11 inch Co...</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>FullDouble Mattress  Never Slept In</td>\n",
       "      <td>['https://images.craigslist.org/00h0h_e1OdRheg...</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>Data/train/cl_sleeping/7562281392.jpg</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.211753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7561155451</td>\n",
       "      <td>Hanging Fruit Hanging glass fruit Never been used</td>\n",
       "      <td>storage</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>Hanging Fruit</td>\n",
       "      <td>['https://images.craigslist.org/00U0U_7JnutRYK...</td>\n",
       "      <td>other</td>\n",
       "      <td>Data/train/cl_other/7561155451.jpg</td>\n",
       "      <td>other</td>\n",
       "      <td>0.252546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7551850196</td>\n",
       "      <td>Benchpadded Sturdy bench</td>\n",
       "      <td>storage</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Benchpadded</td>\n",
       "      <td>['https://images.craigslist.org/01414_75BmImkG...</td>\n",
       "      <td>seating</td>\n",
       "      <td>Data/train/cl_seating/7551850196.jpg</td>\n",
       "      <td>seating</td>\n",
       "      <td>0.205198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                  title_description  \\\n",
       "0  7565015560  Entertainment Center and Hall Tree The Custom ...   \n",
       "1  7564716075  Love seat w recliner This faux leather love se...   \n",
       "2  7562281392  FullDouble Mattress  Never Slept In 11 inch Co...   \n",
       "3  7561155451  Hanging Fruit Hanging glass fruit Never been used   \n",
       "4  7551850196                          Benchpadded Sturdy bench    \n",
       "\n",
       "   prediction_rf  proba_rf                                title  \\\n",
       "0  entertainment  0.679405   Entertainment Center and Hall Tree   \n",
       "1        seating  0.890000                 Love seat w recliner   \n",
       "2       sleeping  0.680000  FullDouble Mattress  Never Slept In   \n",
       "3        storage  0.410000                        Hanging Fruit   \n",
       "4        storage  0.300000                          Benchpadded   \n",
       "\n",
       "                                              images     label  \\\n",
       "0  ['https://images.craigslist.org/00S0S_fi2XJS06...     other   \n",
       "1  ['https://images.craigslist.org/01515_1WBeEG4z...   seating   \n",
       "2  ['https://images.craigslist.org/00h0h_e1OdRheg...  sleeping   \n",
       "3  ['https://images.craigslist.org/00U0U_7JnutRYK...     other   \n",
       "4  ['https://images.craigslist.org/01414_75BmImkG...   seating   \n",
       "\n",
       "                                filepath  prediction_NN  proba_NN  \n",
       "0     Data/train/cl_other/7565015560.jpg  entertainment  0.200292  \n",
       "1   Data/train/cl_seating/7564716075.jpg        seating  0.208093  \n",
       "2  Data/train/cl_sleeping/7562281392.jpg        seating  0.211753  \n",
       "3     Data/train/cl_other/7561155451.jpg          other  0.252546  \n",
       "4   Data/train/cl_seating/7551850196.jpg        seating  0.205198  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect some NaN for filepath as the not all have pictures\n",
    "pred_df = pd.merge(df_proba, test_df, on='id', how='left')\n",
    "#pred_df = test_df.rename(columns={\"label_x\": \"label\", \"label_y\": \"prediction\"})\n",
    "\n",
    "\n",
    "# need to check the probabilities and then assign values\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11ef5969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f3af69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take which ever model is more confident\n",
    "\n",
    "for index, row in pred_df.iterrows():\n",
    "    if row[\"proba_rf\"] > row[\"proba_NN\"] or (np.isnan(row[\"proba_NN\"])):\n",
    "        pred_df.loc[pred_df.index == index, \"prediction_EN\"] = row[\"prediction_rf\"]\n",
    "        pred_df.loc[pred_df.index == index, \"proba_EN\"] = row[\"proba_rf\"]\n",
    "    else:\n",
    "        pred_df.loc[pred_df.index == index, \"prediction_EN\"] = row[\"prediction_NN\"]\n",
    "        pred_df.loc[pred_df.index == index, \"proba_EN\"] = row[\"proba_NN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9635f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "final_total = 0\n",
    "final_correct = 0\n",
    "for index, row in pred_df.iterrows():\n",
    "    if row[\"prediction_EN\"] == row[\"label\"]:\n",
    "        final_correct +=1\n",
    "    final_total += 1\n",
    "print(final_correct/final_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16db6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
