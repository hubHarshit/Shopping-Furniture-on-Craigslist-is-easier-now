{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1f7f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a8d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow.python.keras.preprocessing (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow.python.keras.preprocessing\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow.python.keras.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4523512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.python.keras import optimizers, regularizers\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "from datasets.utils.file_utils import get_datasets_user_agent\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77decd4e-61ce-45fd-852d-493e472e7db4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Downloading the images (Only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8584ce28-184e-4480-9fe2-4f6a17f0e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id       region  \\\n",
      "0     7565015733   tippecanoe   \n",
      "1     7565015560   tippecanoe   \n",
      "2     7565015437   tippecanoe   \n",
      "3     7565015257   tippecanoe   \n",
      "4     7565015081   tippecanoe   \n",
      "...          ...          ...   \n",
      "1294  7547285695  indianoplis   \n",
      "1295  7547287056  indianoplis   \n",
      "1296  7547280827  indianoplis   \n",
      "1297  7547278428  indianoplis   \n",
      "1298  7548087583  indianoplis   \n",
      "\n",
      "                                                  title  \\\n",
      "0                                   Custom Made Dresser   \n",
      "1                    Entertainment Center and Hall Tree   \n",
      "2       Dining Room Table and Kitchen Table Custom Made   \n",
      "3                         Custom Made Bedroom Furniture   \n",
      "4                    Craftsman Style Bookcase Bookshelf   \n",
      "...                                                 ...   \n",
      "1294  Outdoor side table with hole for umbrella nice...   \n",
      "1295              SET OF TWO CAST IRON MOSAIC BAR STOOL   \n",
      "1296      BEAUTIFUL SET OF 3 NESTING TABLES FRUIT PRINT   \n",
      "1297  Conway Wood and cast iron Writing Desk with St...   \n",
      "1298  ORIENTAL ACCENT ENTRY TABLE RED GOLD 32\" l 14\"...   \n",
      "\n",
      "                                            description  \\\n",
      "0     The Custom Cottage makes craftsman hand-made f...   \n",
      "1     The Custom Cottage makes craftsman hand made f...   \n",
      "2     The Custom Cottage makes craftsman hand made f...   \n",
      "3     We make custom furniture for our customers, bu...   \n",
      "4     The Custom Cottage makes craftsman hand made f...   \n",
      "...                                                 ...   \n",
      "1294  Outdoor side table with hole for umbrella nice...   \n",
      "1295  SET OF TWO CAST IRON MOSAIC BAR STOOL 24\" TALL...   \n",
      "1296  BEAUTIFUL SET OF 3 NESTING TABLES FRUIT PRINT ...   \n",
      "1297  Conway Wood and cast iron Writing Desk with St...   \n",
      "1298  ORIENTAL ACCENT ENTRY TABLE RED GOLD 32\" l 14\"...   \n",
      "\n",
      "                                                 images    label  \n",
      "0     [https://images.craigslist.org/00C0C_jBpxpew9v...  storage  \n",
      "1     [https://images.craigslist.org/00S0S_fi2XJS06d...    other  \n",
      "2     [https://images.craigslist.org/00S0S_7YkSep3Qs...    table  \n",
      "3     [https://images.craigslist.org/00b0b_1YhguB5pT...    other  \n",
      "4     [https://images.craigslist.org/00q0q_8NGMnpiFC...  storage  \n",
      "...                                                 ...      ...  \n",
      "1294  [https://images.craigslist.org/00101_bidnhLE9w...    table  \n",
      "1295                                                 []  seating  \n",
      "1296  [https://images.craigslist.org/00909_4FK6Z3YK2...    table  \n",
      "1297                                                 []    table  \n",
      "1298  [https://images.craigslist.org/00S0S_kKJYr7ktz...    table  \n",
      "\n",
      "[1299 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the xlsx\n",
    "# downloading the images to the right directory from craiglist, only the first image, based on label\n",
    "\n",
    "df_load = pd.read_excel(r'listings.xlsx')\n",
    "\n",
    "df = df_load.iloc[:1299, :-1]\n",
    "\n",
    "df[\"images\"] = df[\"images\"].apply(literal_eval)\n",
    "print(df)\n",
    "path = \"Data/train/\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # list of images from listing\n",
    "    image_list = row[\"images\"]\n",
    "    \n",
    "    #pull the first image in the list\n",
    "    try:\n",
    "        image_url = image_list[0]\n",
    "    except:\n",
    "        continue\n",
    "    #set to listing id\n",
    "    image_id = row[\"id\"]\n",
    "    label = row[\"label\"]\n",
    "    image_path = path + \"cl_\" + label + \"/\" + str(image_id) +\".jpg\"\n",
    "    USER_AGENT = get_datasets_user_agent()\n",
    "    \n",
    "    #if the image_url is empty this will break\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        image_url,\n",
    "        data=None,\n",
    "        headers={\"user-agent\": USER_AGENT},\n",
    "    )\n",
    "\n",
    "    if not os.path.isfile(image_path):\n",
    "        with urllib.request.urlopen(request, timeout=None) as req:\n",
    "            image = Image.open(io.BytesIO(req.read()))\n",
    "            image.save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dfa42c-b904-44a7-9d80-ee2065db5e54",
   "metadata": {},
   "source": [
    "### Creating the data to feed to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5b57498-8470-4ba1-921d-fc2a1be1f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pd.DataFrame(columns = [\"filepath\",\"label\"], index=[\"\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cd6efda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7439, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59fbcd8c-f783-40ee-9af8-96e8515d0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "### maps every image path to a label for training\n",
    "\n",
    "path = \"Data/train\"\n",
    "# get all folders in train set\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        directory = entry.name\n",
    "        label = \"\"\n",
    "        if directory == \"bed\":\n",
    "            label = \"sleeping\"\n",
    "        elif directory in [\"sofa\", \"chair\", \"swivelchair\"]:\n",
    "            label = \"seating\"\n",
    "        elif directory == \"table\":\n",
    "            label = \"table\"\n",
    "        elif directory[:3] == \"cl_\":\n",
    "            label = directory[3:]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        #get all images in a specific folder\n",
    "        directory_path = path +\"/\"+entry.name\n",
    "        with os.scandir(directory_path) as files:\n",
    "            for file in files:\n",
    "                img_path = directory_path + \"/\" + file.name\n",
    "                \n",
    "                mappings.loc[len(mappings.index)] = [img_path, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724319f9-798b-4349-9bc5-b8cf81af7103",
   "metadata": {},
   "source": [
    "### Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bd15c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Xception(include_top=False, pooling='avg', weights=\"imagenet\"))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.layers[0].trainable = False\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f31dee9-0802-464f-b95b-343feb781f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO Fix test data to be only CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de151d75-ca14-4ada-a21b-2547c236223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train/val and test sets\n",
    "# Creating a dataframe with 10%\n",
    "# values of original dataframe\n",
    "test_df = mappings.sample(frac = 0.1)\n",
    "\n",
    "# Creating dataframe with\n",
    "# rest of the 90% values\n",
    "train_val_df = mappings.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b84ff194-45bd-4573-9516-36841dfe9472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9567e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5022 validated image filenames belonging to 6 classes.\n",
      "Found 1673 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 299\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                             rescale=1./255.,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             validation_split=0.25)\n",
    "\n",
    "# removed the directory=r\"./furniture_images/\", arg\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=train_val_df,\n",
    "                        x_col=\"filepath\",y_col=\"label\",has_ext=False,\n",
    "                        subset=\"training\",batch_size=32,\n",
    "                        shuffle=True,class_mode=\"categorical\",\n",
    "                        target_size=(image_size, image_size))\n",
    "\n",
    "# removed the directory=r\"./furniture_images\", arg\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "                        dataframe=train_val_df,\n",
    "                        x_col=\"filepath\",\n",
    "                        y_col=\"label\",has_ext=False,\n",
    "                        subset=\"validation\",batch_size=1,\n",
    "                        class_mode=\"categorical\",target_size=(image_size, image_size))\n",
    "\n",
    "\n",
    "# test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1./255.)\n",
    "# test_generator=test_datagen.flow_from_dataframe(\n",
    "#                             dataframe=test_df,\n",
    "#                             directory=\"../input/test/\",x_col=\"id\",\n",
    "#                             y_col=None,has_ext=False,batch_size=1,\n",
    "#                             seed=42,shuffle=False,\n",
    "#                             class_mode=None,target_size=(image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52ee6f7b-665b-454f-b4a9-1f6046f49b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 744 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# generate the test test\n",
    "test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "                            dataframe=test_df,\n",
    "                            x_col=\"filepath\",\n",
    "                            y_col=\"label\",has_ext=False,batch_size=1,\n",
    "                            seed=42,shuffle=False,\n",
    "                            class_mode=None,target_size=(image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0e79e84-01f3-4e8b-85fa-01d29911c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3585686704041922429\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5762973696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5305835505267031641\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c766e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 443/5022 [=>............................] - ETA: 30:55 - loss: 0.4914 - accuracy: 0.8491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22700\\88013776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 _r=1):\n\u001b[0;32m   1186\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=train_generator.n,validation_data=valid_generator,validation_steps=train_generator.n,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577551b8-eddf-4c49-9d9c-6206c62228e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict_generator(test_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f5d0d2d-d25d-43fa-8a06-684f57b0d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "def load(filename):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (256, 256, 3))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n",
    "img = load(\"Data/train/bed/img0.jpg\")\n",
    "pred = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a09db1b8-4e1b-4b59-8f19-a0ff7f6ed5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train/bed/img0.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train/bed/img1.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train/bed/img10.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train/bed/img100.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train/bed/img1000.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filepath     label\n",
       "0     Data/train/bed/img0.jpg  sleeping\n",
       "1     Data/train/bed/img1.jpg  sleeping\n",
       "2    Data/train/bed/img10.jpg  sleeping\n",
       "3   Data/train/bed/img100.jpg  sleeping\n",
       "4  Data/train/bed/img1000.jpg  sleeping"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "670d5303-fe04-4f3f-9468-589d06f8b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entertainment', 'other', 'seating', 'sleeping', 'storage', 'table']\n"
     ]
    }
   ],
   "source": [
    "pred\n",
    "labels = (train_generator.class_indices)\n",
    "labels = list(labels.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "182a684d-7943-4cf3-9eb2-f4eb130d7659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522f592-43de-40e4-8181-477790f36650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
